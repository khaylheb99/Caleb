{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa78a192-d88f-4e3a-b223-51d61b851360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pyl\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb86a3cf-50b6-4f9a-92d2-3bba349ef466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8360700d-b15c-4b0a-a53b-12cf18a43c66",
   "metadata": {},
   "source": [
    "#### Data extraction and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461aabf8-5c32-4d28-ad2d-2a4873b24bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data\n",
    "\n",
    "# Root directory\n",
    "Dir = 'Datasets\\\\animals\\\\'\n",
    "No_of_images = {}\n",
    "\n",
    "for dir in os.listdir(Dir):\n",
    "    No_of_images[dir] = len(os.listdir(os.path.join(Dir, dir)))\n",
    "\n",
    "# Displaying number of images per class available\n",
    "No_of_images.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22202422-d93b-4b36-ae1b-17b1510be95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split data into training, validation and test set\n",
    "\n",
    "def data_selection(X, split):\n",
    "    if not os.path.exists('.\\\\'+X):\n",
    "        os.mkdir('.\\\\'+X)\n",
    "        \n",
    "        for dir in os.listdir(Dir):\n",
    "            os.makedirs('.\\\\'+X+'\\\\'+dir)\n",
    "            for img in np.random.choice(a = os.listdir(os.path.join(Dir, dir)),\n",
    "                                       size = (math.floor(split*No_of_images[dir])-5),\n",
    "                                       replace = False):\n",
    "                O = os.path.join(Dir, dir, img)\n",
    "                D = os.path.join('.\\\\'+X, dir)\n",
    "                shutil.copy(O,D)\n",
    "                os.remove(O)\n",
    "                \n",
    "    else:\n",
    "        print(f'{X} is unavailable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d7f43b-6967-49b0-903f-4613093234d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying data-split funtion\n",
    "\n",
    "data_selection('Train', 0.7)\n",
    "data_selection('Valid', 0.15)\n",
    "data_selection('Test', 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6015d752-60a6-41df-9950-a076d4bf6f93",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6889aa06-228e-4525-8ff8-8458a40aa2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbc6c4ad-d46e-43ec-b2d8-711861767919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess training data\n",
    "\n",
    "def Train_processing(path):\n",
    "    image = ImageDataGenerator(zoom_range = 0.2, shear_range = 0.2,\n",
    "                               preprocessing_function = preprocess_input,\n",
    "                              horizontal_flip = True)\n",
    "    Image = image.flow_from_directory(directory = path, target_size = (224,224),\n",
    "                                     batch_size = 12, class_mode = 'categorical')\n",
    "    return Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84de194e-25e8-4512-92db-56b263da5897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess other data sets\n",
    "\n",
    "def main_processing(path):\n",
    "    image = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "    Image = image.flow_from_directory(directory = path, target_size = (224,224),\n",
    "                                     batch_size = 12, class_mode = 'categorical')\n",
    "    return Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6facc067-fe5d-4690-a711-8940cff71853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying preprocessing functions\n",
    "\n",
    "train = 'C:\\\\Users\\\\PC\\\\Documents\\\\Train'\n",
    "valid = 'C:\\\\Users\\\\PC\\\\Documents\\\\Valid'\n",
    "test = 'C:\\\\Users\\\\PC\\\\Documents\\\\Test'\n",
    "\n",
    "Train = Train_processing(train)\n",
    "Valid = main_processing(valid)\n",
    "Test = main_processing(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17ad3fb-c5f8-46b5-af05-e4525b6529ba",
   "metadata": {},
   "source": [
    "#### Model importation and modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75852b30-560a-436a-8425-d63a2e4acb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet import MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f8d7bf-a1c7-40e2-a1a8-52dfc66c05e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating imported model\n",
    "\n",
    "Base_model = MobileNet(input_shape = (224, 224, 3), include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a53f6e-166f-4067-a5ef-922a3dccd011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model info\n",
    "\n",
    "Base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9180ef5d-35e3-43b4-86c6-ac81797d70fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Base_model.layers:\n",
    "    i.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ba16f1-5108-40fb-9b49-753557963844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Flattening and final dense layer to model\n",
    "\n",
    "Output = Flatten()(Base_model.output)\n",
    "Out = Dense(4, activation = 'softmax')(Output)\n",
    "\n",
    "model = Model(Base_model.input, Out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cc81b0-6663-497f-8787-c1d255600ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified model info\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aac8c93-f71f-4f11-b669-1b10578c7dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = 'rmsprop', \n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ff882c-b044-4437-85fa-4514f46208cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting model\n",
    "\n",
    "hist_=model.fit_generator(Train, steps_per_epoch = 12, epochs = 25,\n",
    "                   validation_data = Valid, validation_steps = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc23b21b-32f9-45e6-bb4a-33a2d183fbdb",
   "metadata": {},
   "source": [
    "#### Model evaluation and deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab69f9e7-b8da-48be-aebf-3901ad17eb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "\n",
    "model.evaluate_generator(Valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1886aaf0-6a4d-4e61-84c5-ffe68d6f8e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = hist_.history\n",
    "\n",
    "H.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e12d9b-4a3e-40d2-bf7e-5851f0f190fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy plot\n",
    "\n",
    "plt.plot(H['accuracy'], c = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f04913e-c742-43e6-b449-4c66fb6cb28f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loss plot\n",
    "\n",
    "plt.plot(H['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b2b79f-96ad-42e1-a6d5-b93db2906f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "Pred_img = Cnn_model_1.predict(Test)\n",
    "N_pred = np.argmax(Pred_img, axis = 1)\n",
    "N_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9540dca4-ddab-478c-b72a-a6cdcf8b1a05",
   "metadata": {},
   "source": [
    "A new function is created to classify any random image of a cheetah, leopard, lion or tiger.\n",
    "This just requires the path to the image and the model classifies this image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b067de0a-ec84-420a-93c5-8d48585f8bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1127f448-29dc-4be7-89e1-703353a31790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Image_classes_prediction(path, model):\n",
    "    img = load_img(path, target_size = (224, 224))\n",
    "    in_arr = img_to_array(img)\n",
    "    in_arr = preprocess_input(in_arr)\n",
    "    plt.imshow(in_arr)\n",
    "    in_arr = np.expand_dims(in_arr, axis = 0)\n",
    "    \n",
    "    Pred = model.predict(in_arr)\n",
    "    Pred_ = np.argmax(Pred)\n",
    "    \n",
    "    if Pred_ == 0:\n",
    "        print('Cheetah')\n",
    "    elif Pred_ == 1:\n",
    "        print('Leopard')\n",
    "    elif Pred_ == 2:\n",
    "        print('Lion')\n",
    "    else:\n",
    "        print('Tiger')\n",
    "        \n",
    "    return Pred_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5444ed-fa46-4a1f-98a5-ac4b7080adb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Leo = ''\n",
    "Image_classes_prediction(Leo, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
